---
title: "Weekly Work: Kernel Analysis"
format:
  html:
    code-fold: true
jupyter: python3
---

## Week 3

Due to the timing issues, we continue with the plan of comparing kernels. For a simple analysis we look at the first layer of each model and output all of it's kernels and compare for the different models based on differing sizes of dataset.

::: {#fig-kernelAnalysisInitial layout-ncol=3}

![250 snapshots trained model, kernel [0,0]](figures/week3/250Filter0kernel0.png){#fig-week3data250kernel0}

![250 snapshots trained model, kernel [0,1]](figures/week3/250Filter0kernel1.png){#fig-week3data250kernel1}

![250 snapshots trained model, kernel [0,2]](figures/week3/250Filter0kernel2.png){#fig-week3data250kernel2}

![500 snapshots trained model, kernel [0,0]](figures/week3/500Filter0kernel0.png){#fig-week3data500kernel0}

![500 snapshots trained model, kernel [0,1]](figures/week3/500Filter0kernel1.png){#fig-week3data500kernel1}

![500 snapshots trained model, kernel [0,2]](figures/week3/500Filter0kernel2.png){#fig-week3data500kernel2}

![750 snapshots trained model, kernel [0,0]](figures/week3/750Filter0kernel0.png){#fig-week3data750kernel0}

![750 snapshots trained model, kernel [0,1]](figures/week3/750Filter0kernel1.png){#fig-week3data750kernel1}

![750 snapshots trained model, kernel [0,2]](figures/week3/750Filter0kernel2.png){#fig-week3data750kernel2}

![1000 snapshots trained model, kernel [0,0]](figures/week3/1000Filter0kernel0.png){#fig-week3data1000kernel0}

![1000 snapshots trained model, kernel [0,1]](figures/week3/1000Filter0kernel1.png){#fig-week3data1000kernel1}

![1000 snapshots trained model, kernel [0,2]](figures/week3/1000Filter0kernel2.png){#fig-week3data1000kernel2}

![1250 snapshots trained model, kernel [0,0]](figures/week3/1250Filter0kernel0.png){#fig-week3data1250kernel0}

![1250 snapshots trained model, kernel [0,1]](figures/week3/1250Filter0kernel1.png){#fig-week3data1250kernel1}

![1250 snapshots trained model, kernel [0,2]](figures/week3/1250Filter0kernel2.png){#fig-week3data1250kernel2}

Comparison of the first layer of kernels for each model trained on different amounts of data.
:::

---

## Week 4

The work from week 3 to 4 was to use a datset of image filter matrices and compare them to the kernels generated by our model to see if the neural network had learned the filtes without their input. This would show the model to be doing edge analysis for example if it predominantly used edge analysis filters. To do this, edge_filter.ipynb was crated and contains the relevant code to perform this. At this point a few kernels and filters appeared relatively similar but with a few key differences such as one matrix element much larger than in the filter.

```{python}

import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np

from skimage import filters
from sklearn.preprocessing import normalize 

name = "week1/0.1_full"
model = tf.keras.models.load_model(f'../models/{name}.keras')

kernels, biases = model.layers[0].get_weights()

# Get filters
I = np.zeros((3,3))
I[1,1] = 1

my_filter_dict = {}
plot = False
for f in dir(filters):
  if f != "try_all_threshold":   # This one causes some to be drawn and just calls the other thresholds which are already checked
    try:
        filter = eval(f"filters.{f}(I)")
        if filter.shape == (3,3):
            my_filter_dict[f] = filter
            if plot:
                plt.matshow(filter)
                plt.title(f)
                plt.figure()
    except Exception as e:
        # print(f,"with exception", e)
      f = 0

# Normalise matrices
normalised_kernels = np.copy(kernels)
normalised_filters = my_filter_dict.copy()

index = 0
for kernel in normalised_kernels:
    kernel = (kernel - kernel.min())
    kernel = kernel/kernel.max()
    kernel /= kernel.sum()

    normalised_kernels[index] = kernel
    index += 1

index = 0
filter_keys = list(normalised_filters.keys())
for filter in normalised_filters.values():
    filter_key = filter_keys[index]

    filter = (filter - filter.min())
    # Some filters have all the same value so doing this causes divide by zero error, instead set all to 1.
    if (filter.max() == filter.min()):
        filter.fill(1)
    else:
        filter = filter/filter.max()
    filter /= filter.sum()
    normalised_filters[filter_key] = filter
    
    index += 1


## Compare Matrices:
differences_dict = {}
kernel_index = 0
for kernel in normalised_kernels:
    kernel = kernel.squeeze()
    filter_index = 0
    for filter in normalised_filters.values():
        filter_key = list(my_filter_dict.keys())[filter_index]
        for roll in range(0,4):   # All 4 rotations
            sum = np.sum(np.abs(kernel - filter))
            differences_dict[f"kernel-{kernel_index},filter-{filter_key},roll-{roll}"] = (sum)
            kernel = np.array(list(zip(*kernel))[::-1])
        filter_index += 1
    kernel_index += 1
            

# sort by value
sorted_differences_dict = {k: v for k, v in sorted(differences_dict.items(), key=lambda item: item[1])} 

plt.plot(sorted_differences_dict.values(),'.')
plt.xlabel("Index of similarity")
plt.ylabel("Sum of differences between matrices")
```

The values on the lowest end are the kernels and filters have the closest values to. 

```{python}
closest_key = list(sorted_differences_dict.keys())[0]
closest_value = sorted_differences_dict[closest_key]
print("Closest Key is " + str(closest_key) + " with a total difference of " + str(closest_value))


kernel = normalised_kernels[0].squeeze()
plt.matshow(kernel, cmap="binary")
plt.colorbar()

plt.matshow(normalised_filters['farid'], cmap='binary')
plt.colorbar()
```

However, also of interest is the values that are furthest from each other as shown here:

```{python}
furthest_key = list(sorted_differences_dict.keys())[-1]
furthest_value = sorted_differences_dict[furthest_key]
print("Furthest Key is " + str(furthest_key) + " with a total difference of " + str(furthest_value))


kernel = normalised_kernels[0].squeeze()
for i in range(3):  # Need to roll 3 times
    kernel = np.array(list(zip(*kernel))[::-1])
plt.matshow(kernel, cmap="binary")
plt.colorbar()

plt.matshow(normalised_filters['unsharp_mask'], cmap='binary')
plt.colorbar()
```

Here we have basically the complete opposite filter has appeared. There are other results that we could look into as well, such as finding which filtrer is closest to each kernel: 

```{python}
name0 = 'kernel-0'
name1 = 'kernel-1'
name2 = 'kernel-2'
kernel_0_dict = {}
kernel_1_dict = {}
kernel_2_dict = {}

for f in sorted_differences_dict.keys():
    if name0 in f:
        kernel_0_dict[f]=sorted_differences_dict[f]
    elif name1 in f:
        kernel_1_dict[f]=sorted_differences_dict[f]
    elif name2 in f:
        kernel_2_dict[f]=sorted_differences_dict[f]

closest_key = list(kernel_1_dict.keys())[0]
closest_value = kernel_1_dict[closest_key]
print("Closest key for kernel 1 is " + str(closest_key) + " with a total difference of " + str(closest_value))


kernel = normalised_kernels[1].squeeze()
for i in range(3):  # Need to roll 3 times
    kernel = np.array(list(zip(*kernel))[::-1])
plt.matshow(kernel, cmap="binary")
plt.colorbar()

plt.matshow(normalised_filters['scharr_h'], cmap='binary')
plt.colorbar()
```